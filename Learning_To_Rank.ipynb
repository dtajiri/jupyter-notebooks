{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtajiri/jupyter-notebooks/blob/master/Learning_To_Rank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKrjg_MS-5_t"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Disclaimer: The colab was ran locally due to limited RAM when connected to a hosted runtime\n",
        "\n",
        "### path directory can be modified to run on viewer's local machine\n"
      ],
      "metadata": {
        "id": "kh9zlJAYN1KJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdtz-fNP-eq7"
      },
      "source": [
        "### 1) Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQbF5lfeQ7B-"
      },
      "outputs": [],
      "source": [
        "# Import dependencies here\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1am1Iv_LWR2W"
      },
      "source": [
        "### 2) Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xdQI3jD4wiY",
        "outputId": "00370d8b-bf9d-4c0d-fa6d-38be169e4787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0          1    2    3    4    5    6    7          8           9    \\\n",
              "0         2      qid:1  1:3  2:3  3:0  4:0  5:3  6:1        7:1         8:0   \n",
              "1         2      qid:1  1:3  2:0  3:3  4:0  5:3  6:1        7:0         8:1   \n",
              "2         0      qid:1  1:3  2:0  3:2  4:0  5:3  6:1        7:0  8:0.666667   \n",
              "3         2      qid:1  1:3  2:0  3:3  4:0  5:3  6:1        7:0         8:1   \n",
              "4         1      qid:1  1:3  2:0  3:3  4:0  5:3  6:1        7:0         8:1   \n",
              "...     ...        ...  ...  ...  ...  ...  ...  ...        ...         ...   \n",
              "723407    0  qid:29992  1:2  2:0  3:1  4:1  5:2  6:1        7:0   8:0.50000   \n",
              "723408    0  qid:29992  1:2  2:1  3:1  4:1  5:2  6:1  7:0.50000   8:0.50000   \n",
              "723409    0  qid:29992  1:2  2:2  3:2  4:2  5:2  6:1        7:1         8:1   \n",
              "723410    0  qid:29992  1:2  2:0  3:0  4:0  5:2  6:1        7:0         8:0   \n",
              "723411    1  qid:29992  1:2  2:1  3:1  4:0  5:2  6:1  7:0.50000   8:0.50000   \n",
              "\n",
              "        ...           129     130        131        132     133     134  \\\n",
              "0       ...  128:11089534   129:2    130:116  131:64034  132:13   133:3   \n",
              "1       ...  128:11089534   129:2    130:124  131:64034   132:1   133:2   \n",
              "2       ...         128:3   129:1    130:124   131:3344  132:14  133:67   \n",
              "3       ...  128:11089534  129:13    130:123  131:63933   132:1   133:3   \n",
              "4       ...         128:5   129:7    130:256  131:49697   132:1  133:13   \n",
              "...     ...           ...     ...        ...        ...     ...     ...   \n",
              "723407  ...         128:7   129:2  130:13829  131:35302  132:21   133:8   \n",
              "723408  ...         128:0   129:0  130:26074  131:35101  132:14   133:7   \n",
              "723409  ...        128:11   129:2   130:2995  131:62170   132:4   133:8   \n",
              "723410  ...         128:0   129:0    130:138  131:56419   132:4   133:3   \n",
              "723411  ...       128:131   129:0  130:13556  131:25675   132:2  133:12   \n",
              "\n",
              "          135    136    137 138  \n",
              "0       134:0  135:0  136:0 NaN  \n",
              "1       134:0  135:0  136:0 NaN  \n",
              "2       134:0  135:0  136:0 NaN  \n",
              "3       134:0  135:0  136:0 NaN  \n",
              "4       134:0  135:0  136:0 NaN  \n",
              "...       ...    ...    ...  ..  \n",
              "723407  134:0  135:0  136:0 NaN  \n",
              "723408  134:1  135:0  136:0 NaN  \n",
              "723409  134:0  135:0  136:0 NaN  \n",
              "723410  134:0  135:0  136:0 NaN  \n",
              "723411  134:0  135:0  136:0 NaN  \n",
              "\n",
              "[723412 rows x 139 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>qid:1</td>\n",
              "      <td>1:3</td>\n",
              "      <td>2:3</td>\n",
              "      <td>3:0</td>\n",
              "      <td>4:0</td>\n",
              "      <td>5:3</td>\n",
              "      <td>6:1</td>\n",
              "      <td>7:1</td>\n",
              "      <td>8:0</td>\n",
              "      <td>...</td>\n",
              "      <td>128:11089534</td>\n",
              "      <td>129:2</td>\n",
              "      <td>130:116</td>\n",
              "      <td>131:64034</td>\n",
              "      <td>132:13</td>\n",
              "      <td>133:3</td>\n",
              "      <td>134:0</td>\n",
              "      <td>135:0</td>\n",
              "      <td>136:0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>qid:1</td>\n",
              "      <td>1:3</td>\n",
              "      <td>2:0</td>\n",
              "      <td>3:3</td>\n",
              "      <td>4:0</td>\n",
              "      <td>5:3</td>\n",
              "      <td>6:1</td>\n",
              "      <td>7:0</td>\n",
              "      <td>8:1</td>\n",
              "      <td>...</td>\n",
              "      <td>128:11089534</td>\n",
              "      <td>129:2</td>\n",
              "      <td>130:124</td>\n",
              "      <td>131:64034</td>\n",
              "      <td>132:1</td>\n",
              "      <td>133:2</td>\n",
              "      <td>134:0</td>\n",
              "      <td>135:0</td>\n",
              "      <td>136:0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>qid:1</td>\n",
              "      <td>1:3</td>\n",
              "      <td>2:0</td>\n",
              "      <td>3:2</td>\n",
              "      <td>4:0</td>\n",
              "      <td>5:3</td>\n",
              "      <td>6:1</td>\n",
              "      <td>7:0</td>\n",
              "      <td>8:0.666667</td>\n",
              "      <td>...</td>\n",
              "      <td>128:3</td>\n",
              "      <td>129:1</td>\n",
              "      <td>130:124</td>\n",
              "      <td>131:3344</td>\n",
              "      <td>132:14</td>\n",
              "      <td>133:67</td>\n",
              "      <td>134:0</td>\n",
              "      <td>135:0</td>\n",
              "      <td>136:0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>qid:1</td>\n",
              "      <td>1:3</td>\n",
              "      <td>2:0</td>\n",
              "      <td>3:3</td>\n",
              "      <td>4:0</td>\n",
              "      <td>5:3</td>\n",
              "      <td>6:1</td>\n",
              "      <td>7:0</td>\n",
              "      <td>8:1</td>\n",
              "      <td>...</td>\n",
              "      <td>128:11089534</td>\n",
              "      <td>129:13</td>\n",
              "      <td>130:123</td>\n",
              "      <td>131:63933</td>\n",
              "      <td>132:1</td>\n",
              "      <td>133:3</td>\n",
              "      <td>134:0</td>\n",
              "      <td>135:0</td>\n",
              "      <td>136:0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>qid:1</td>\n",
              "      <td>1:3</td>\n",
              "      <td>2:0</td>\n",
              "      <td>3:3</td>\n",
              "      <td>4:0</td>\n",
              "      <td>5:3</td>\n",
              "      <td>6:1</td>\n",
              "      <td>7:0</td>\n",
              "      <td>8:1</td>\n",
              "      <td>...</td>\n",
              "      <td>128:5</td>\n",
              "      <td>129:7</td>\n",
              "      <td>130:256</td>\n",
              "      <td>131:49697</td>\n",
              "      <td>132:1</td>\n",
              "      <td>133:13</td>\n",
              "      <td>134:0</td>\n",
              "      <td>135:0</td>\n",
              "      <td>136:0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723407</th>\n",
              "      <td>0</td>\n",
              "      <td>qid:29992</td>\n",
              "      <td>1:2</td>\n",
              "      <td>2:0</td>\n",
              "      <td>3:1</td>\n",
              "      <td>4:1</td>\n",
              "      <td>5:2</td>\n",
              "      <td>6:1</td>\n",
              "      <td>7:0</td>\n",
              "      <td>8:0.50000</td>\n",
              "      <td>...</td>\n",
              "      <td>128:7</td>\n",
              "      <td>129:2</td>\n",
              "      <td>130:13829</td>\n",
              "      <td>131:35302</td>\n",
              "      <td>132:21</td>\n",
              "      <td>133:8</td>\n",
              "      <td>134:0</td>\n",
              "      <td>135:0</td>\n",
              "      <td>136:0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723408</th>\n",
              "      <td>0</td>\n",
              "      <td>qid:29992</td>\n",
              "      <td>1:2</td>\n",
              "      <td>2:1</td>\n",
              "      <td>3:1</td>\n",
              "      <td>4:1</td>\n",
              "      <td>5:2</td>\n",
              "      <td>6:1</td>\n",
              "      <td>7:0.50000</td>\n",
              "      <td>8:0.50000</td>\n",
              "      <td>...</td>\n",
              "      <td>128:0</td>\n",
              "      <td>129:0</td>\n",
              "      <td>130:26074</td>\n",
              "      <td>131:35101</td>\n",
              "      <td>132:14</td>\n",
              "      <td>133:7</td>\n",
              "      <td>134:1</td>\n",
              "      <td>135:0</td>\n",
              "      <td>136:0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723409</th>\n",
              "      <td>0</td>\n",
              "      <td>qid:29992</td>\n",
              "      <td>1:2</td>\n",
              "      <td>2:2</td>\n",
              "      <td>3:2</td>\n",
              "      <td>4:2</td>\n",
              "      <td>5:2</td>\n",
              "      <td>6:1</td>\n",
              "      <td>7:1</td>\n",
              "      <td>8:1</td>\n",
              "      <td>...</td>\n",
              "      <td>128:11</td>\n",
              "      <td>129:2</td>\n",
              "      <td>130:2995</td>\n",
              "      <td>131:62170</td>\n",
              "      <td>132:4</td>\n",
              "      <td>133:8</td>\n",
              "      <td>134:0</td>\n",
              "      <td>135:0</td>\n",
              "      <td>136:0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723410</th>\n",
              "      <td>0</td>\n",
              "      <td>qid:29992</td>\n",
              "      <td>1:2</td>\n",
              "      <td>2:0</td>\n",
              "      <td>3:0</td>\n",
              "      <td>4:0</td>\n",
              "      <td>5:2</td>\n",
              "      <td>6:1</td>\n",
              "      <td>7:0</td>\n",
              "      <td>8:0</td>\n",
              "      <td>...</td>\n",
              "      <td>128:0</td>\n",
              "      <td>129:0</td>\n",
              "      <td>130:138</td>\n",
              "      <td>131:56419</td>\n",
              "      <td>132:4</td>\n",
              "      <td>133:3</td>\n",
              "      <td>134:0</td>\n",
              "      <td>135:0</td>\n",
              "      <td>136:0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723411</th>\n",
              "      <td>1</td>\n",
              "      <td>qid:29992</td>\n",
              "      <td>1:2</td>\n",
              "      <td>2:1</td>\n",
              "      <td>3:1</td>\n",
              "      <td>4:0</td>\n",
              "      <td>5:2</td>\n",
              "      <td>6:1</td>\n",
              "      <td>7:0.50000</td>\n",
              "      <td>8:0.50000</td>\n",
              "      <td>...</td>\n",
              "      <td>128:131</td>\n",
              "      <td>129:0</td>\n",
              "      <td>130:13556</td>\n",
              "      <td>131:25675</td>\n",
              "      <td>132:2</td>\n",
              "      <td>133:12</td>\n",
              "      <td>134:0</td>\n",
              "      <td>135:0</td>\n",
              "      <td>136:0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>723412 rows × 139 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Download the dataset located at https://storage.googleapis.com/personalization-takehome/MSLR-WEB10K.zip\n",
        "# You can read about the features included in the dataset here: \n",
        "# https://www.microsoft.com/en-us/research/project/mslr/\n",
        "\n",
        "# Load dataset\n",
        "train = pd.read_csv('Downloads/MSLRWEB10K/Fold1/train.txt', sep=' ', header=None)\n",
        "test = pd.read_csv('Downloads/MSLRWEB10K/Fold1/test.txt', sep=' ', header=None)\n",
        "val = pd.read_csv('Downloads/MSLRWEB10K/Fold1/vali.txt', sep=' ', header=None)\n",
        "\n",
        "# visualize raw data frame\n",
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQdKuIDNWVb8"
      },
      "source": [
        "### 3) Preprocess and evaluate the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHEqbC9sOrvb"
      },
      "outputs": [],
      "source": [
        "# Create a dict to rename columns of the data frame\n",
        "d = dict()\n",
        "d[0] = 'relevance'\n",
        "d[1] = 'qid'\n",
        "for x in range(2,138):\n",
        "    d[x]=f'{x-1}'\n",
        "\n",
        "# change format of data so that table entries dont include the lables (i.e 'qid' and the feature number)\n",
        "\n",
        "# train set\n",
        "train.rename(columns=d,inplace = True)\n",
        "train.drop(columns=train.columns[-1], axis=1,inplace=True)\n",
        "for i in range(137):\n",
        "  x = []\n",
        "  for j in list(train.iloc[:, i+1]):\n",
        "    x.append(j.split(':')[1])\n",
        "  train.iloc[:, i+1] = x\n",
        "    \n",
        "# test set\n",
        "test.rename(columns=d,inplace = True)\n",
        "test.drop(columns=test.columns[-1], axis=1,inplace=True)\n",
        "for i in range(137):\n",
        "  x = []\n",
        "  for j in list(test.iloc[:, i+1]):\n",
        "    x.append(j.split(':')[1])\n",
        "  test.iloc[:, i+1] = x \n",
        "\n",
        "\n",
        "# validation set\n",
        "val.rename(columns=d,inplace = True)\n",
        "val.drop(columns=val.columns[-1], axis=1,inplace=True)\n",
        "for i in range(137):\n",
        "    x = []\n",
        "    for j in list(val.iloc[:, i+1]):\n",
        "        x.append(j.split(':')[1])\n",
        "    val.iloc[:, i+1] = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBOgm8bK4wia",
        "outputId": "1ffde204-4b9a-473f-a1d7-7945a1c29db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The amount of queries in the train dataset:  6000\n",
            "The amount of queries in the test dataset:  2000\n",
            "The amount of queries in the validation dataset:  2000 \n",
            "\n",
            "* different queries have different amounts of documents related to it *\n",
            "The amount of documents associated with qid 1 in train dataset:  86\n",
            "The amount of documents associated with qid 16 in train dataset:  106\n",
            "The amount of documents associated with qid 31 in train dataset:  92\n",
            "\n",
            "* As seen below, some queries have no documents that are relevant *\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       relevance    qid  1  2  3  4  5  6  7         8  ... 127 128 129  \\\n",
              "75480          0  10045  3  0  0  0  3  1  0         0  ...  37  13   0   \n",
              "75481          0  10045  0  0  0  0  0  0  0         0  ...  20   0   0   \n",
              "75482          0  10045  3  0  3  2  3  1  0         1  ...  62   1   0   \n",
              "75484          0  10045  3  3  3  0  3  1  1         1  ...  38   2   2   \n",
              "75509          0  10045  3  0  1  0  3  1  0  0.333333  ...  22   0   0   \n",
              "\n",
              "         130    131 132  133 134 135               136  \n",
              "75480   6447  11640   1   18   0   0                 0  \n",
              "75481  50217   9776   1   88   0   2              82.8  \n",
              "75482   1185  45660  16   18   0   0                 0  \n",
              "75484    191  30773  18  118   0   0                 0  \n",
              "75509  61604  25504   1    4   0  14  30.4161904761905  \n",
              "\n",
              "[5 rows x 138 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relevance</th>\n",
              "      <th>qid</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75480</th>\n",
              "      <td>0</td>\n",
              "      <td>10045</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>37</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6447</td>\n",
              "      <td>11640</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75481</th>\n",
              "      <td>0</td>\n",
              "      <td>10045</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50217</td>\n",
              "      <td>9776</td>\n",
              "      <td>1</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>82.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75482</th>\n",
              "      <td>0</td>\n",
              "      <td>10045</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1185</td>\n",
              "      <td>45660</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75484</th>\n",
              "      <td>0</td>\n",
              "      <td>10045</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>191</td>\n",
              "      <td>30773</td>\n",
              "      <td>18</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75509</th>\n",
              "      <td>0</td>\n",
              "      <td>10045</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>61604</td>\n",
              "      <td>25504</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>30.4161904761905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 138 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "* Compared to the query above, the query with qid 10 has documents that have relevance ranging from 0 - 4 *\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    relevance qid  1  2  3  4  5         6  7         8  ... 127   128 129  \\\n",
              "0           0  10  2  0  0  0  2  0.666667  0         0  ...  45     1   0   \n",
              "33          0  10  0  0  0  0  0         0  0         0  ...  10     0   0   \n",
              "34          0  10  3  0  3  0  3         1  0         1  ...  47     7   1   \n",
              "37          0  10  0  0  0  0  0         0  0         0  ...  35    11   3   \n",
              "39          0  10  1  0  1  0  1  0.333333  0  0.333333  ...  11     0   0   \n",
              "..        ...  .. .. .. .. .. ..       ... ..       ...  ...  ..   ...  ..   \n",
              "60          2  10  3  0  3  3  3         1  0         1  ...  97     6   0   \n",
              "59          3  10  3  0  3  0  3         1  0         1  ...  20  1896   1   \n",
              "73          4  10  3  0  3  0  3         1  0         1  ...  30  1883   1   \n",
              "23          4  10  3  0  3  0  3         1  0         1  ...  34  1943   1   \n",
              "25          4  10  3  0  3  0  3         1  0         1  ...  30  1884   1   \n",
              "\n",
              "      130    131 132  133   134  135               136  \n",
              "0     117  55115   7    2     0    0                 0  \n",
              "33  27378   2561  62  157     0    0                 0  \n",
              "34   1890  34192   2    1     0    0                 0  \n",
              "37   5145  61346   1    1     0    0                 0  \n",
              "39  62543  34399   1    1     0  318  60.0168778961509  \n",
              "..    ...    ...  ..  ...   ...  ...               ...  \n",
              "60  20177  33213   1    6     0    0                 0  \n",
              "59  21725  35216   1    1     5    0                 0  \n",
              "73  48645  35168   1    1  2241  426  30.1554670902879  \n",
              "23  46900  34605   1    1     0    4               5.8  \n",
              "25  46238  34605   1    1     0   12  71.2380952380952  \n",
              "\n",
              "[93 rows x 138 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relevance</th>\n",
              "      <th>qid</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>117</td>\n",
              "      <td>55115</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27378</td>\n",
              "      <td>2561</td>\n",
              "      <td>62</td>\n",
              "      <td>157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>47</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1890</td>\n",
              "      <td>34192</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>35</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>5145</td>\n",
              "      <td>61346</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>62543</td>\n",
              "      <td>34399</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>318</td>\n",
              "      <td>60.0168778961509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>97</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>20177</td>\n",
              "      <td>33213</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>1896</td>\n",
              "      <td>1</td>\n",
              "      <td>21725</td>\n",
              "      <td>35216</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>30</td>\n",
              "      <td>1883</td>\n",
              "      <td>1</td>\n",
              "      <td>48645</td>\n",
              "      <td>35168</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2241</td>\n",
              "      <td>426</td>\n",
              "      <td>30.1554670902879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>34</td>\n",
              "      <td>1943</td>\n",
              "      <td>1</td>\n",
              "      <td>46900</td>\n",
              "      <td>34605</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>30</td>\n",
              "      <td>1884</td>\n",
              "      <td>1</td>\n",
              "      <td>46238</td>\n",
              "      <td>34605</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>71.2380952380952</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>93 rows × 138 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# To see the amount of queries in each dataset\n",
        "\n",
        "train_groups = pd.DataFrame({'qid': train['qid'], 'relevance' :train['relevance']}).groupby('qid')\n",
        "test_groups = pd.DataFrame({'qid': test['qid'], 'relevance' :test['relevance']}).groupby('qid')\n",
        "val_groups = pd.DataFrame({'qid': val['qid'], 'relevance' :val['relevance']}).groupby('qid')\n",
        "print('The amount of queries in the train dataset: ', len(pd.DataFrame({'qid': train['qid'], 'relevance' :train['relevance']}).groupby('qid').groups))\n",
        "print('The amount of queries in the test dataset: ', len(test_groups.groups))\n",
        "print('The amount of queries in the validation dataset: ', len(val_groups.groups),'\\n')\n",
        "\n",
        "print('* different queries have different amounts of documents related to it *')\n",
        "print('The amount of documents associated with qid 1 in train dataset: ', len(train_groups.groups['1']))\n",
        "print('The amount of documents associated with qid 16 in train dataset: ',len(train_groups.groups['16']))\n",
        "print('The amount of documents associated with qid 31 in train dataset: ',len(train_groups.groups['31']))\n",
        "\n",
        "qid_10045 = val[val.qid =='10045']\n",
        "print('\\n* As seen below, some queries have no documents that are relevant *')\n",
        "display(qid_10045.sort_values(by = 'relevance').tail()) # sort lists the entries from lowest to highest\n",
        "\n",
        "qid_10 = val[val.qid =='10']\n",
        "print('\\n* Compared to the query above, the query with qid 10 has documents that have relevance ranging from 0 - 4 *')\n",
        "display(qid_10.sort_values(by = 'relevance')) # sort lists the entries from lowest to highest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAHUaH1v4wib"
      },
      "outputs": [],
      "source": [
        "# Define the X data and y labels for Linear Regression\n",
        "\n",
        "X_train = train[train.columns[2:]]\n",
        "y_train = train['relevance']\n",
        "X_test = test[test.columns[2:]]\n",
        "y_test = test['relevance']\n",
        "X_val = val[val.columns[2:]]\n",
        "y_val = val['relevance']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L48tMvml4wic"
      },
      "outputs": [],
      "source": [
        "# Convert to XGBoost Data Matrix for XGB LambdaMart Ranking model\n",
        "\n",
        "XGB_training_data = xgb.DMatrix('Downloads/MSLRWEB10K/Fold1/train.txt')\n",
        "XGB_testing_data = xgb.DMatrix('Downloads/MSLRWEB10K/Fold1/test.txt')\n",
        "XGB_validation_data = xgb.DMatrix('Downloads/MSLRWEB10K/Fold1/vali.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OICi0aAuWclQ"
      },
      "source": [
        "### 4) Build ranking model and test on validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJXpR3YB4wid"
      },
      "source": [
        "###### Learning to Rank with Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IZQcukA4wid"
      },
      "outputs": [],
      "source": [
        "# Fit Linear Regression model to data using sklearn\n",
        "regr = LinearRegression()\n",
        "regr.fit(X_train,y_train)\n",
        "regr.score(X_train,y_train) #goodness of fit\n",
        "\n",
        "# getting predictions for validation set\n",
        "lin_reg_pred_val = regr.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaE2qSm84wie"
      },
      "outputs": [],
      "source": [
        "# create functions to compute nDCG\n",
        "\n",
        "def ndcg_at_k(truth, prediction, k=None):\n",
        "    \"\"\"Returns normalized Discounted Cumulative Gain\n",
        "    Args:\n",
        "        truth (1-D Array): list of relevance in true order\n",
        "        prediction (1-D Array): list of relevance in predicted order\n",
        "        k (int): nDCG calculated on first k entries, default = None\n",
        "    Returns:\n",
        "        ndcg (float): normalized Discounted Cumulative Gain score [0,1] at k\"\"\"\n",
        "    truth = np.sort(truth)[::-1] #sort truth array from highest to lowest relevance\n",
        "    k = min(len(prediction), k) #k will be the minimum of either the length of the data or use given k\n",
        "    log_den = 1 / (np.log2(np.arange(1,k+1) + 1)) #create an array for dcg and idcg denominator\n",
        "    idcg = np.sum(truth[:k] * log_den) #summation of truth value * log denominator array\n",
        "    dcg = np.sum(prediction[:k] * log_den) #summation of predicted value * log denominator array\n",
        "    \n",
        "    return dcg/idcg #return nDCG\n",
        "\n",
        "# function used to apply to all qid groups\n",
        "def all_ndcg_at_k(group, k=None):\n",
        "    truth = np.array(group.truth.tolist())\n",
        "    prediction = np.array(group.sort_values(by = \"predicted\").truth.tolist())\n",
        "    return ndcg_at_k(truth,prediction,k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A9k-iQF4wif",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "5e7da87d-5cb8-4019-d67f-648b9a0f18e5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "qid\n",
              "10       0.516668\n",
              "100      0.608987\n",
              "1000     0.446300\n",
              "10000    0.338311\n",
              "10015    0.453043\n",
              "10030    0.500000\n",
              "10045         NaN\n",
              "10060    0.687932\n",
              "10075    0.490889\n",
              "10090    0.168788\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* NaN values are due to querries that have documents that are all 0 in the relevant scale *\n"
          ]
        }
      ],
      "source": [
        "lin_reg_pred_df = pd.DataFrame({'qid': val['qid'], 'truth' :y_val, 'predicted' : lin_reg_pred_val})\n",
        "lin_reg_groups = lin_reg_pred_df.groupby('qid')\n",
        "lin_reg_ndcg_score = lin_reg_groups.apply(all_ndcg_at_k, k=100) \n",
        "display(lin_reg_ndcg_score.head(10))\n",
        "print('* NaN values are due to querries that have documents that are all 0 in the relevant scale *')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imkt2VNH4wif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2a676db-26aa-48b8-df45-b977a6dca8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error is: 0.6051755110970498\n",
            "The average of all the qid group nDCGs: 0.47256748855540126\n",
            "* average nDCG scores increase as k increase *\n"
          ]
        }
      ],
      "source": [
        "# evaluating how well model does on validation set\n",
        "mse = mean_squared_error(lin_reg_pred_val, y_val)\n",
        "print(f'The Mean Squared Error is: {mse}')\n",
        "print(f'The average of all the qid group nDCGs:', np.nanmean(lin_reg_ndcg_score)) \n",
        "print('* average nDCG scores increase as k increase *')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YVm64Yt4wig",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "4bb6dd98-2df8-49d2-f9fc-b9fa7d34c4c7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From the above graph, we can tell that:\n",
            "\t • documents with higher relevance have smaller predicted score ranges (range not including outliers)\n",
            "\t • predicted scores range from around -14 to 7\n",
            "\t • documents with relevance of 0 has the most variation/outliers in predicted score\n"
          ]
        }
      ],
      "source": [
        "plt.scatter(x=y_val, y=lin_reg_pred_val, c = 'navy', alpha = .4)\n",
        "\n",
        "plt.xlabel('True Labels', fontsize=14)\n",
        "plt.ylabel('Predicted Scores', fontsize=14)\n",
        "plt.title('Actual vs Predicted Scores', fontsize = 17)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('From the above graph, we can tell that:')\n",
        "print('\\t \\u2022 documents with higher relevance have smaller predicted score ranges (range not including outliers)')\n",
        "print('\\t \\u2022 predicted scores range from around -14 to 7')\n",
        "print('\\t \\u2022 documents with relevance of 0 has the most variation/outliers in predicted score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqoCqOAV4wih"
      },
      "source": [
        "###### Learning to Rank with XGBoost LambdaRank (Pair-wise Ranking) and LambdaMart (List-wise Ranking) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg2gFdZW4wih"
      },
      "outputs": [],
      "source": [
        "# LamdaRank (Pair-wise Ranking)\n",
        "\n",
        "# Define the model and fit to data \n",
        "lambdaRank_model = xgb.train(\n",
        "    {'objective':'rank:pairwise',\n",
        "     'max_depth': 2,\n",
        "     'eta': 0.1,\n",
        "     'seed': 279,\n",
        "     'tree_method': 'approx'},\n",
        "    XGB_training_data,\n",
        "    num_boost_round = 5)\n",
        "\n",
        "# Predict scores\n",
        "lr_pred = lambdaRank_model.predict(XGB_validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXYPCCbg4wii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "93d127f3-95e4-4d59-a418-6b394d82c152"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "qid\n",
              "10       0.531915\n",
              "100      0.578286\n",
              "1000     0.513512\n",
              "10000    0.410372\n",
              "10015    0.397349\n",
              "10030    0.630930\n",
              "10045         NaN\n",
              "10060    0.699835\n",
              "10075    0.533585\n",
              "10090    0.195328\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error is:  0.6962045418899816\n",
            "The average of all the qid group nDCGs: 0.49277894921586435\n"
          ]
        }
      ],
      "source": [
        "# Create data frame of qid, true labels, and predicted scores\n",
        "lr_pred_df = pd.DataFrame({'qid': val['qid'], 'truth':y_val, 'predicted': lr_pred})\n",
        "\n",
        "# group data by qid\n",
        "lr_groups = lr_pred_df.groupby('qid')\n",
        "\n",
        "# calculate nDCG on all qid groups\n",
        "lr_ndcg_score = lr_groups.apply(all_ndcg_at_k, k=100) \n",
        "display(lr_ndcg_score.head(10))\n",
        "print('The Mean Squared Error is: ', mean_squared_error(lr_pred, y_val))\n",
        "print('The average of all the qid group nDCGs:', np.nanmean(lr_ndcg_score)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frHrBKmTSUsq"
      },
      "outputs": [],
      "source": [
        "# LamdaMart (List-wise Ranking)\n",
        "\n",
        "# Define the model and fit to data \n",
        "lambdaMart_model = xgb.train(\n",
        "    {'objective':'rank:ndcg',\n",
        "     'max_depth': 2,\n",
        "     'eta': 0.1,\n",
        "     'seed': 279,},\n",
        "    XGB_training_data,\n",
        "    num_boost_round = 5)\n",
        "\n",
        "# Predict scores\n",
        "lm_pred = lambdaMart_model.predict(XGB_validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GozCSco4wij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "e26abbdc-a13b-49b0-d840-1fc2ec8bef90"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "qid\n",
              "10       0.538541\n",
              "100      0.598432\n",
              "1000     0.532945\n",
              "10000    0.407622\n",
              "10015    0.390917\n",
              "10030    0.630930\n",
              "10045         NaN\n",
              "10060    0.682414\n",
              "10075    0.462021\n",
              "10090    0.246491\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error is:  0.690297870335471\n",
            "The average of all the qid group nDCGs: 0.5038547445714483\n"
          ]
        }
      ],
      "source": [
        "# Create data frame of qid, true labels, and predicted scores\n",
        "lm_pred_df = pd.DataFrame({'qid': val['qid'], 'truth':y_val, 'predicted': lm_pred})\n",
        "lm_groups = lm_pred_df.groupby('qid')\n",
        "lm_ndcg_score = lm_groups.apply(all_ndcg_at_k, k=100) \n",
        "display(lm_ndcg_score.head(10))\n",
        "print('The Mean Squared Error is: ', mean_squared_error(lm_pred, y_val))\n",
        "print('The average of all the qid group nDCGs:', np.nanmean(lm_ndcg_score)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCtsO41X4wij"
      },
      "outputs": [],
      "source": [
        "#Since LambdaMart produced the best nDCG score, we'll continue to use the model\n",
        "\n",
        "# Define the model with different eta and fit to data \n",
        "# adjusting eta allows for correction of over/under fitting\n",
        "lambdaMart_model_small_eta = xgb.train(\n",
        "    {'objective':'rank:ndcg',\n",
        "     'max_depth': 2,\n",
        "     'eta': 0.0000001,\n",
        "     'seed': 279,},\n",
        "    XGB_training_data,\n",
        "    num_boost_round = 5)\n",
        "\n",
        "# Predict scores\n",
        "lm_pred_small_eta = lambdaMart_model_small_eta.predict(XGB_validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6ujk_r74wik",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "43a86968-52d2-4393-aea3-5df0bdf79e32"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "qid\n",
              "10       0.546666\n",
              "100      0.592464\n",
              "1000     0.551302\n",
              "10000    0.402560\n",
              "10015    0.395734\n",
              "10030    0.630930\n",
              "10045         NaN\n",
              "10060    0.746701\n",
              "10075    0.518688\n",
              "10090    0.314994\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error is:  0.7205877279315275\n",
            "The average of all the qid group nDCGs: 0.5206019427409502\n"
          ]
        }
      ],
      "source": [
        "# Create data frame of qid, true labels, and predicted scores\n",
        "lm_pred_small_eta_df = pd.DataFrame({'qid': val['qid'], 'truth':y_val, 'predicted': lm_pred_small_eta})\n",
        "\n",
        "# group data by qid\n",
        "lm_small_eta_groups = lm_pred_small_eta_df.groupby('qid')\n",
        "\n",
        "# calculate nDCG on all qid groups\n",
        "lm_small_eta_ndcg_score = lm_small_eta_groups.apply(all_ndcg_at_k, k=100) \n",
        "display(lm_small_eta_ndcg_score.head(10))\n",
        "print('The Mean Squared Error is: ', mean_squared_error(lm_pred_small_eta, y_val))\n",
        "print('The average of all the qid group nDCGs:', np.nanmean(lm_small_eta_ndcg_score)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBtVqWRSWx_g"
      },
      "source": [
        "### 5) Evaluate model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpaP8jesTQMj"
      },
      "source": [
        "###### Out of the 3 models shown above, the XGBoost LambdaMart model performed the best on the validation set. Therefore, I will be evaluating that model's performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoUoDcCq4wil",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "885b9695-2ecc-4da6-a722-c2c35812fbe4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "qid\n",
              "10003    0.458293\n",
              "10018         NaN\n",
              "1003     0.542167\n",
              "10033    0.433920\n",
              "10048    0.406465\n",
              "10063    0.375651\n",
              "10078    0.388718\n",
              "10093    0.517295\n",
              "10108    0.166358\n",
              "10123    0.497726\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error is:  0.7253292595164605\n",
            "The average of all the qid group nDCGs: 0.5167650855540964\n"
          ]
        }
      ],
      "source": [
        "# Predict scores using the small eta model\n",
        "final_pred = lambdaMart_model_small_eta.predict(XGB_testing_data)\n",
        "\n",
        "# Create data frame of qid, true labels, and predicted scores\n",
        "final_pred_df = pd.DataFrame({'qid': test['qid'], 'truth':y_test, 'predicted': final_pred})\n",
        "\n",
        "# group data by qid\n",
        "final_groups = final_pred_df.groupby('qid')\n",
        "\n",
        "# calculate nDCG on all qid groups\n",
        "final_ndcg_score = final_groups.apply(all_ndcg_at_k, k=100) \n",
        "display(final_ndcg_score.head(10))\n",
        "print('The Mean Squared Error is: ', mean_squared_error(final_pred, y_test))\n",
        "print('The average of all the qid group nDCGs:', np.nanmean(final_ndcg_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo89zS_g--XG"
      },
      "source": [
        "# Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of thought process and reasoning behind models and evaluation metrics used**"
      ],
      "metadata": {
        "id": "roMcnD6Gj4gj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ruh_6aWuZX_"
      },
      "source": [
        "There were 3 models that I tested for this project, which are linear regression for point-wise ranking, lambdaRank for pair-wise ranking, and lambdaMart for list-wise ranking. There are many reasons why I decided to evaluate 3 different models. These some of the reason are that:\n",
        "- Linear regression is a commonly used model in ML and is a model I'm very familiar with, so it was interesting to see it's effectiveness in learning to rank.\n",
        "- Decision trees (XGBoost's lambdaMart) are also very popular among supervised learning methods and I wanted to familiarize myself with XGBoost's library.\n",
        "- I wanted to explore and gain more experience in deep learning models, which is why I decided to use XGBoost's lambdaRank (a neural network)\n",
        "- The final model I decided on using for testing was lambdaMart due to it having performed the best in terms of nDCG score on the validation set.\n",
        "\n",
        "I chose 2 different metrics to evaluate my models: Mean Squared Error (MSE) and Normalized Discounted Cumulative Gain (nDCG).\n",
        "- I decided to use MSE because linear regression works to minimize MSE, therefore I wanted to see how well the model performed in terms of minimizing it's loss function compared to the minimizing MSE performance of the other models. In term's of minimizing MSE the linear regression model did the best, but in terms of average nDCG score among the query groups it produced the worst result.\n",
        "- An nDCG score ranges from 0 to 1 (1 means that the rankings were 100% accurate and the list returned was the optimal list, whereas 0 means the model performed terribly). The reason for chooosing nDCG as a metric of evaluation is that it is a better determination of success in terms of learning to rank. It takes into consideration that we care more about the difference in top ranking documents and positions rather than the bottom part of the ranking list. I decided on using the nDCG@k metric since it takes into consideration only the k (k in this case was 100) top documents, which is better in terms of comparing how well the models did among query groups of all different sizes.\n",
        "- Compare to MSE, nDCG is a better metric due to the fact that MSE measures accuracy depending on the distance between predicted scores and true ranking position rather than the diffrence in predicted rank and true rank. Predicted scores don't have as much meaning to the objective as the predicted rank does. Therefore, the metric I put more emphasis on improving was the nDCG score.\n",
        "\n",
        "In terms of final model (lambdaMart/List-wise ranking) performace, my model produced a 51.7% accuracy. This accuracy is dependent on only the top 100 ranked documents for each query. I believe good accuracy and performace is dependent on the situation. If was wanted to produce the exact same ranking list given, then 51.7% wouldn't be as ideal. However, I believe that everyone wouldn't have the exact same ranking list in mind when searching a query. For better words, what one person deems a relevant document might not be the same as what another deems relevant. Because of this, I believe it is okay to have a little room for error in terms of nDCG score. Given this, I think performance accuracy of 60%-80% would be ideal and my model doesn't quite hit the mark.\n",
        "\n",
        "If I had more time, I would have wanted to explore the linear regression model a little more. Compared to the the neural network and decision tree it didn't too horribly with an accuracy score of 47.3% on the validation set. In order to improve the model, I would have tested for multicollinearity by looking at the feature's Variance Inflation Factor. I'd also want to analyzed the feature's p-values to determine their significance.\n",
        "\n",
        "Id also want to explore and learn more in depth about XGBoost's model parameters and how they could help me increase accuracy. For example, the 'eta' parameter used above for the lambdaMart and lambdaRank models is used for ensuring that there isn't over/under fitting, which is why my performace increased when I lowered the size of the parameter.\n",
        "\n",
        "I would also have wanted to try these models all the different data files available. I was only able to train, validate, and test on the files in folder 1, but it'd be interesting to see if the performance would change if the model were trained and tested on a different data set."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Other features that could provide to be of help towards the performace of the three models:**"
      ],
      "metadata": {
        "id": "aPz_oBlAjiot"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJGp9xC2uVK3"
      },
      "source": [
        "I believe that user_id would be a great feature to include, this is because relevancey could depend on the user that is searching the query. I think along with user_id another feature that could help would be data on previously searched queries. If a user has searched a query and didn't find a document fit to their needs, they would likely rephrase the query. Having data on previously search queries could offer a way to ensure that the user doesnt keep seeing the same top documents even after rephrasing their query. \n",
        "\n",
        "Access to features like query_text, title_text, body_text, and document_url could also prove to be helpful. If given access to features, I could put more emphasis on certain words in the query. For example, words like \"who\", \"what\", \"why\", \"when\", and \"where\" provide more importance to ranking results than words like 'a', 'the', 'it', etc. By putting emphasis on certain words in the query text, we can determine a score on how often it appears in the title, body, or url. We could also determine how soon in the document that the words are seen. Url information is also very important, especially domain name. If creating a search engine, we wouldn't want to list dangerous documents at the top even though they might perfectly match the query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy73cbghWBM3"
      },
      "source": [
        "### 8) Please submit your colab by sharing it with: cmaon@oreilly.com and rlandry@oreilly.com\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Learning To Rank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}